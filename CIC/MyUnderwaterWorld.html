<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
   
    <title>MyUnderwaterWorld</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
</head>

        <!-- you should probably put some google analytics / meta bits and pieces
	    here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '??????????');
  </script>
    -->

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1>MyUnderwaterWorld: Intelligent Underwater Scene Representation</h1>
                                <h4>Underwater Scene Enhancement and 3D Modelling</h4>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.svg" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <p><img src="underwater_enh.png" width="100%" /></p>
                <p align="right">(Left) Raw video by Piyapong Suwannakul and (Right) Processed video using <a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html" target="_blank">VI-Lab tools</a>. See video <a href="https://www.youtube.com/embed/sLL2D--731M" target="_blank">HERE</a></p>

                <h2 id="aim">Aim</h2>
                <p>Our oceans have been explored for hundreds of years and these activities are becoming increasingly important because of the need to  manage and conserve mineral and biological resources effectively, as well as to better understand planetary-scale processes including tectonics and marine hazards.  Exploration and analysis are however always limited by the number of diving experts, technologies, and in particular, costs. Advanced imaging methods now support a new paradigm of remote discovery where onshore experts with specific knowledge, such as geologists, archaeologists and biologists, are able to remotely model and explore underwater scenes. </p>

                <p>Underwater environment represents the combination of several challenges. Water is a dynamic medium and suspended particles move. Light scatter causes blur and halo effects, whilst light absorption leads to colour distortion and reduced contrast. The model of underwater imagery should thus comprise temporally- and spatially-variant distortion, uneven intensity bias,  multiplicative noise, and additive noise. This project aims to exploit underwater image priors to perform 3D mapping process can be done directly from the raw underwater sequences. </p>

        <div class="row">
        <div class="col">
        <dt>Collaborators</dt>
            <dd>National Park Service Submerged Resources Center, Woods Hole Oceanographic Institute, Marine Imaging Technologies, National Oceanic and Atmospheric Administration, Gates Underwater Products, Esprit Film & Television</dd>
        </div>
        </div>
        <div class="row">
        <div class="col">
        <dt>Funder</dt>
            <dd>EPSRC ECR International Collaboration Grant (EP/Y002490/1), UKRI MyWorld Strength in Places Programme (SIPF00006/1)</dd>
        </div>
        </div>
        <hr />
        <div class="row">
        <div class="col">
        <h2 id="downloads">Research team</h2>
            <h5 id="coreteam">Core</h5>
            <ul>
                <li><a href='https://pui-nantheera.github.io/'>N. Anantrasirichai</a>: Lead academic</li>
                <li><a href=''>Postdoctoral researcher</a>: Recruiting</li>
                <li><a href=''>Haoran Wang</a>: PhD student</li>
            </ul>
            <h5 id="UGteam">Undergrad/Postgrad projects</h5>
            <ul>
                <li>Luca Gough (2023/2024), 3D Representations of Underwater Scenes using 3D Gaussian Splatting</li>
                <li>George Atkinson (2023/2024), Underwater image and video enhancement</li> 
            </ul>
        </div>
        </div>
            </div>
            <hr />
            <!--
            <div class="container-md">
                <h2 id="downloads">Downloads</h2>
                <h5 id="UGteam">Publications</h5>
                <ul>
                    <li><a>Topological Loss Function for Image Denoising on a new BVI-lowlight Dataset</a>. A. Malyugina, N. Anantrasirichai, and D. Bull. Signal Processing. 2023. [<a href="https://www.sciencedirect.com/science/article/pii/S016516842300155X">PDF</a>]</li>
                    <li><a>Contextual colorization and denoising for low-light ultra high resolution sequences</a>. N. Anantrasirichai and D. Bull.  In Proceedings of the IEEE International Conference on Image Processing. 2021 <pdf>[</pdf><a href="https://arxiv.org/pdf/2101.01597.pdf">PDF</a><pdf>]</pdf> </li>
                </ul>
                <h5 id="UGteam">Datasets</h5>
                <ul>
                    <li>Paired image dataset for image denoising <a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">[dataset]</a> <a href="https://www.sciencedirect.com/science/article/pii/S016516842300155X">[paper]</a></li>
                    <li>Paired video dataset for low-light enhancement <a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">[dataset]</a></li>
                    <li>Unpaired UHD video dataset  <a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html">[dataset]</a> <a href="https://ieeexplore.ieee.org/document/9506694">[paper]</a> </li>
                </ul>
            </div>
            <hr />
            -->
            
            <div class="container-md">
                <h2 id="related">Related research</h2>
                <h5 id="downloads">Related publications from VI-Lab</h5>
                <ul>
                    <li><a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html" target="_blank">A unified framework for contextual lighting, colorization and denoising for UHD sequences </a>. N Anantrasirichai and D R Bull. IEEE ICIP, 2021</li>
                    <li><a href="https://arxiv.org/pdf/2007.12391.pdf">Artificial intelligence in the creative industries: A review</a>. N Anantrasirichai and D R Bull, Artif Intell Rev 55, 2022</li>
                    <li><a href="https://arxiv.org/abs/2302.08455">ST-MFNet Mini: Knowledge distillation-driven frame interpolation</a>. C Morris, D Danier, F Zhang, N Anantrasirichai, D R Bull. IEEE International Conference on Image Processing. 2023 </li>
                </ul>
                <h5 id="downloads">Denoising in different modalities</h5>
                <ul>
                    <li><a href="https://seis.bristol.ac.uk/~eexna/papers/retinal_img_enhance.pdf">Adaptive-weighted bilateral filtering for optical coherence tomography</a></li>
                    <li><a href="https://ieeexplore.ieee.org/document/9323696">Despeckling SAR Images of the Sea Surface</a></li>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/9160976">Solving SAR Imaging Inverse Problems Using Nonconvex Regularization</a></li>
                    <li><a href="https://www-sigproc.eng.cam.ac.uk/foswiki/pub/Main/NGK/Anantrasirichai_etal_draft_jrnl_12jul2012_c.pdf">Mitigating The Effects of Atmospheric Distortion</a></li>
                </ul>
            </div>
          

        </div>
    </div>
</body>

</html>
