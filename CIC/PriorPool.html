<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
   
    <title>PriorPool</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="../favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon_io/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
</head>

        <!-- you should probably put some google analytics / meta bits and pieces
	    here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '??????????');
  </script>
    -->

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1>PriorPool: Intelligent Video Restoration and Enhancement via a Large Prior Database</h1>
                                
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.svg" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <p><img src="underwater_enh.png" width="100%" /></p>
                <p align="right">(Left) Raw video by Piyapong Suwannakul and (Right) Processed video using <a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html" target="_blank">VI-Lab tools</a>. See video <a href="https://www.youtube.com/embed/sLL2D--731M" target="_blank">HERE</a></p>

                <h2 id="aim">Aim</h2>
                <p>Acquiring high-quality video in challenging conditions—such as low light, heat haze, or adverse weather—is difficult, often resulting in degraded footage that hinders both human and machine interpretation. PriorPool addresses this by leveraging priors from high-quality videos with similar content to guide restoration and enhancement. The project develops an unsupervised framework that tackles blind inverse problems, combining robust content representations, prior retrieval, and context-aware optimisation. By exploiting the knowledge embedded in high-quality videos, PriorPool aims to overcome information loss and the lack of ground truth, enabling more accurate and effective video restoration. </p>

              

        <div class="row">
        <div class="col">
        <dt>Collaborators</dt>
            <dd><a href='https://www.bbc.co.uk/rd' target="_blank">BBC R&D</a>, <a href="https://www.lavfx.com/" target="_blank">Lux Aeterna VFX</a>, <a href="https://www.espritfilm.co.uk/" target="_blank">Esprit Film and Television</a>, <a href='https://www.myworld-creates.com/' target="_blank">MyWorld</a></p></dd>
        </div>
        </div>
        <div class="row">
        <div class="col">
        <dt>Funder</dt>
            <dd>EPSRC New Investigator Award</dd>
        </div>
        </div>
        <hr />

        <div class="row">
        <div class="col">
        <h2 id="downloads">Research team</h2>
            <!-- <h5 id="coreteam">Core</h5> -->
            <ul>
                <li><a href='https://pui-nantheera.github.io/'>N. Anantrasirichai</a>: Lead academic</li>
                <li><a href='https://research-information.bris.ac.uk/en/persons/alexandra-malyugina'>Alexandra Malyugina</a>: Postdoctoral researcher, [<a href="https://arxiv.org/abs/2507.08375">Paper1</a>] [<a href="https://arxiv.org/abs/2504.19289">Paper2</a>]</li>
                <li><a href='https://russellllaputa.github.io/'>Guoxi Huang (Edward)</a>: Postdoctoral researcher, <pdf>[</pdf><a href="https://arxiv.org/pdf/2501.14265">Paper1</a><pdf>]</pdf> <pdf>[</pdf><a href="https://www.arxiv.org/abs/2505.01869">Paper2</a><pdf>]</pdf> </li> </li>
                <li><a href=''>Yini Li</a>: PhD student (Co-supervisor: <a href='https://david-bull.github.io/' target="_blank">Prof David Bull</a>), <pdf>[</pdf><a href="https://openaccess.thecvf.com/content/WACV2025/hthttps://arxiv.org/abs/2503.11175">Paper</a><pdf>]</pdf> </li>
                <li>PhD Student [</pdf><a href="https://pui-nantheera.github.io/phd_offer.html">Scholarship</a><pdf>] </li>
            </ul>
            
        </div> 
        </div>
            </div>
            <hr />
            
            <div class="container-md">
                <h2 id="downloads">Downloads</h2>
                <h5 id="UGteam">Publications</h5> 
                <ul>
                    
                    <li><span style="color:#C71585;">[Shortlist Best Student Paper Award]</span> <a>Zero-TIG: Temporal Consistency-Aware Zero-Shot Illumination-Guided Low-light Video Enhancement</a>. Y Li and N Anantrasirichai. 33rd European Signal Processing Conference, 2025 <pdf>[</pdf><a href="https://arxiv.org/pdf/2503.11175">PDF</a><pdf>]</pdf> </li>
                    
                </ul> 
                <h5 id="UGteam">White papers</h5>
                <ul>
                    <li><a>Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques</a>, A Malyugina, Y Li, J Lin, N Anantrasirichai, 2025 [<a href="https://arxiv.org/abs/2507.08375">PDF</a>] </li>
                    
                </ul>
                <h5 id="UGteam">Datasets</h5>
                <ul>
                    <li>Paired video dataset for low-light enhancement [<a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">dataset</a>] [<a href="https://arxiv.org/pdf/2407.03535">arXiv</a>]</li>
                    <li>Paired image dataset for image denoising [<a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">dataset</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S016516842300155X">paper</a>]</li>
                    <li>Unpaired UHD video dataset  [<a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html">dataset</a>] [<a href="https://ieeexplore.ieee.org/document/9506694">paper</a>] </li>
                    
                </ul>
            </div>
            <hr />
            
            
            <div class="container-md">
                <h2 id="related">Related research</h2>
                <h5 id="downloads">Related publications from VI-Lab</h5>
                <ul>
                    <li><a>BVI-Mamba: video enhancement using a visual state-space model for low-light and underwater environments</a>. G Huang, R Lin, Y Li, D Bull, N Anantrasirichai. Machine Learning from Challenging Data, 2025 <pdf>[</pdf><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13460/1346009/BVI-Mamba--video-enhancement-using-a-visual-state-space/10.1117/12.3053998.short">PDF</a><pdf>]</pdf> [<a href="https://github.com/russellllaputa/BVI-Mamba">CODE</a>]</li>
                    <li><a>Marine Snow Removal Using Internally Generated Pseudo Ground Truth</a>. A Malyugina, G Huang, E Ruiz, B Leslie, N Anantrasirichai. 33rd European Signal Processing Conference, 2025 <pdf>[</pdf><a href="https://arxiv.org/abs/2504.19289">PDF</a><pdf>]</pdf> </li>
                    <li><a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html" target="_blank">A unified framework for contextual lighting, colorization and denoising for UHD sequences </a>. N Anantrasirichai and D R Bull. IEEE ICIP, 2021</li>
                    <li><a href="https://arxiv.org/pdf/2007.12391.pdf">Artificial intelligence in the creative industries: A review</a>. N Anantrasirichai and D R Bull, Artif Intell Rev 55, 2022</li>
                    <li><a href="https://arxiv.org/abs/2302.08455">ST-MFNet Mini: Knowledge distillation-driven frame interpolation</a>. C Morris, D Danier, F Zhang, N Anantrasirichai, D R Bull. IEEE International Conference on Image Processing. 2023 </li>
                </ul>
                <h5 id="downloads">Denoising in different modalities</h5>
                <ul>
                    <li><a href="https://seis.bristol.ac.uk/~eexna/papers/retinal_img_enhance.pdf">Adaptive-weighted bilateral filtering for optical coherence tomography</a></li>
                    <li><a href="https://ieeexplore.ieee.org/document/9323696">Despeckling SAR Images of the Sea Surface</a></li>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/9160976">Solving SAR Imaging Inverse Problems Using Nonconvex Regularization</a></li>
                    <li><a href="https://www-sigproc.eng.cam.ac.uk/foswiki/pub/Main/NGK/Anantrasirichai_etal_draft_jrnl_12jul2012_c.pdf">Mitigating The Effects of Atmospheric Distortion</a></li>
                </ul>
            </div>
          

        </div>
    </div>
</body>

</html>
