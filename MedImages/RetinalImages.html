<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
   
    <title>OcularImaging</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="../favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon_io/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
</head>

        <!-- you should probably put some google analytics / meta bits and pieces
	    here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '??????????');
  </script>
    -->

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1>Computer Assisted Analysis of Ocular Imaging</h1>
                                <h4>Enhancement, Segmentation, Registration, Fusion and Classification</h4>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.svg" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <p align="center"><img src="Retinal_teaser.jpg" width="100%" /></p>
                <p align="right"> Adaptive-Weighted Bilateral Filtering and Other Pre-processing Techniques for Optical Coherence Tomography (<a href="http://www.sciencedirect.com/science/article/pii/S0895611114001050" target="_blank">CMIG, 2014</a>)</p>

                <h2 id="aim">Aim</h2>
                <p>This project aims to develop advanced image analysis tools to maximise the information inherent in retinal images. This comprehensive approach encompasses several key methodologies: enhancement to improve image quality, segmentation to isolate critical structures, registration to align images from different modalities, fusion to integrate complementary data, and classification to diagnose and monitor ocular conditions. The focus is on leveraging these techniques across various imaging modalities, including color fundus photography, optical coherence tomography (OCT), and confocal microscopy. By integrating these tools, the project seeks to provide a robust framework for the detailed analysis and interpretation of retinal images, facilitating early detection, diagnosis, and treatment of ocular diseases. This multidisciplinary effort aims to contribute significantly to the field of ophthalmology, offering enhanced diagnostic capabilities and ultimately improving patient outcomes. </p>

        <div class="row">
        <div class="col">
        <dt>Collaborators</dt>
            <dd>School of Optometry and Vision Sciences (Cardiff University)</dd>
        </div>
        <div class="col">
        <dt>Funder</dt>
            <dd>China Scholarship Council (CSC)</dd>
        </div>
        </div>
        <hr />
        <div class="row">
        <div class="col">
        <h2 id="downloads">Research team</h2>
            <!-- <h5 id="coreteam">Core</h5> -->
            <ul>
                <li><a href='https://research-information.bris.ac.uk/en/persons/alin-m-achim'>Alin Achim</a>, <a href='https://pui-nantheera.github.io/'>N. Anantrasirichai</a> and <a href='https://www.bristol.ac.uk/people/person/Lindsay-Nicholson-1b81aee5-6258-4249-812d-48abaa5e4690/'>Lindsay Nicholson</a>: Lead academics</li>
                <li><a href='https://scholar.google.com/citations?user=hqGvJY0AAAAJ&hl=en'>Xin Tian</a>: PhD student</li>
            </ul>
          
        </div>
        </div>
        <hr />    
        <h2 id="downloads">Methods</h2>
        <div class="row">
        <div class="col">
        
            <!-- <h5 id="coreteam">Core</h5> -->
            <ul>
                <li><a href='https://github.com/xintian-99/TaGAT'>Multi-modal Retinal Image Fusion (TaGAT)</a> (MICCAI2024) <p align="left"><img src="TaGAT_diagram.jpg" width="100%" /></p></li>
                <li><a href='https://github.com/xintian-99/OCT2Confocal_3DCycleGAN'>Multi-modal Retinal Image Translation (OCT2Confocal)</a> (ISBI2024) <p align="left"><img src="OCT2Confocal_diagram.jpg" width="90%" /></p></li>
                <li><a href='https://arxiv.org/pdf/2203.00069'>3D retinal OCT image registration</a> (ICIP2022) <p align="left"><img src="OCTRegis_diagram.jpg" width="100%" /></li>
                
            </ul>
          
        </div>
        <div class="col">
            <ul>
                <li><a href='https://arxiv.org/pdf/2407.10667'>Texture-based glaucoma classification</a> (ISIB2013) <p>An automated texture classification method for glaucoma was developed, utilising robust principal component analysis of texture descriptors. A multi-modal information fusion technique included visual field measurements, OCT, and retinal fundus photography.</p><p align="left"><img src="glaucoma_SVM.jpg" width="80%" /></p>
                    </li>
                <li><a href='https://seis.bristol.ac.uk/~eexna\papers\retinal_img_enhance.pdf'>Adaptive-Weighted Bilateral Filtering</a> (ICIP2013) <p>The method removes speckle while preserving useful retinal layer information using multi-scale despeckling based on a dual-tree complex wavelet transform (DT-CWT). Further enhancement is achieved through a novel adaptive-weighted bilateral filter (AWBF) that preserves texture.</p><p align="left"><img src="OCTdespeckling.jpg" width="80%" /></p></li>
                
            </ul>
          
        </div>
        </div>
            </div>
            <hr />
            
            <div class="container-md">
                <h2 id="downloads">Downloads</h2>
                <h5 id="UGteam">Publications</h5> 
                <ul>
                    <li><a>TaGAT: Topology-Aware Graph Attention Network For Multi-modal Retinal Image Fusion</a>. X Tian, N Anantrasirichai, L Nicholson, A Achim. Medical Image Computing and Computer Assisted Intervention (MICCAI). 2024 <pdf>[</pdf><a href="https://arxiv.org/pdf/2407.14188">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://github.com/xintian-99/TaGAT">Code</a><pdf>]</pdf></li>
                    <li><a>OCT2Confocal: 3D CycleGAN based Translation of Retinal OCT Images to Confocal Microscopy</a>. X Tian, N Anantrasirichai, L Nicholson, A Achim. IEEE International Symposium on Biomedical Imaging. 2024 <pdf>[</pdf><a href="https://arxiv.org/abs/2311.10902">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://github.com/xintian-99/OCT2Confocal_3DCycleGAN">Code</a><pdf>]</pdf></li>
                    <li><a>Optimal Transport-based Graph Matching for 3D retinal OCT image registration</a>. X Tian, N Anantrasirichai, L Nicholson, A Achim. IEEE International Conference on Image Processing. 2022. <pdf>[</pdf><a href="https://arxiv.org/pdf/2203.00069.pdf">PDF</a><pdf>]</pdf> </li>
                    <li><a>Textural Feature Analysis of Optical Coherence Tomography Phantoms</a>. M. Kulmaganbetov, R J Bevan, N. Anantrasirichai, Alin Achim, I. Erchova, N. White, J. Albon, J E Morgan.  Electronics. 2022. <pdf>[</pdf><a href="https://www.mdpi.com/2079-9292/11/4/669">PDF</a><pdf>]</pdf> </li>
                    <li><a>Exploiting texture information in diagnosing Glaucoma</a>. E.T. Gormus, N. Anantrasirichai, M. Bundy, I. Erchova, N. White, J. Fergusson, J. Morgan, L.B. Nicholson, A. Achim. In Proceedings of the IEEE Signal Processing and Communications Applications Conference (SIU). 2017 <pdf>[</pdf><a href="http://ieeexplore.ieee.org/document/7960648/">PDF</a><pdf>]</pdf></li>
                    <li><a>Adaptive-Weighted Bilateral Filtering and Other Pre-processing Techniques for Optical Coherence Tomography</a>. N. Anantrasirichai, L. Nicholson, J. E. Morgan, I. Erchova, K. Mortlock, R. V. North, J. Albon, and Alin Achim. Computerized Medical Imaging and Graphics. 2014 <pdf>[</pdf><a href="https://seis.bristol.ac.uk/~eexna\papers\retinal_img_enhance.pdf">PDF</a><pdf>]</pdf>  <pdf>[</pdf><a href="http://www.sciencedirect.com/science/article/pii/S0895611114001050" target="_blank">BibTeX</a><pdf>]</pdf></li>
                    <li><a>Adaptive-weighted bilateral filtering for Optical Coherence Tomography</a>. N. Anantrasirichai, L. Nicholson, J. E. Morgan, I. Erchova, and Alin Achim. In Proceedings of the IEEE International Conference on Image Processing (ICIP 2013). <pdf>[</pdf><a href="https://seis.bristol.ac.uk/~eexna\papers\OCTicip.pdf">PDF</a><pdf>]</pdf></li>
                    <li><a>SVM-based texture classification in optical coherence tomography</a>. N. Anantrasirichai, Alin Achim, J. E. Morgan, I. Erchova, and L. Nicholson. In Proceedings of the IEEE International Symposium on Biomedical Imaging (ISIB 2013). <pdf>[</pdf><a href="https://seis.bristol.ac.uk/~eexna\papers\ISBIpaper.pdf">PDF</a><pdf>]</pdf></li>
                    <li><a>Curvelet domain image fusion of OCT and fundus imagery using convolution of meridian distributions</a>. O. Pappas, N. Anantrasirichai, L. Nicholson, J. E. Morgan, I. Erchova, and Alin Achim. In Proceedings of the IEEE International Conference on Image Processing (ICIP 2013). <pdf>[</pdf><a href="https://seis.bristol.ac.uk/~eexna\papers\retinalICIP2013.pdf">PDF</a><pdf>]</pdf></li>
                </ul> 
                <h5 id="UGteam">Datasets</h5> 
                <ul>
                    
                    
                </ul> 
            </div>
            <hr />
            
            
            <div class="container-md">
                <h2 id="related">Related research</h2>
                <h5 id="downloads">Related publications from VI-Lab</h5>
                <ul>
                    <li><a>PMT: Partial-Modality Translation Based on Diffusion Models for Prostate Magnetic Resonance and Ultrasound Image Registration</a>. X Ma, N Anantrasirichai, S Bolomytis, A Achim. Medical Image Understanding and Analysis. 2024 <pdf>[</pdf><a href="https://link.springer.com/chapter/10.1007/978-3-031-66958-3_21">PDF</a><pdf>]</pdf> </li>
                    <li><a>DUBLINE: A Deep Unfolding Network for B-line Detection in Lung Ultrasound Imagesy</a>. T Yang, N Anantrasirichai, O Karakuş, M Allinovi, HC Koydemir, A Achim. IEEE International Symposium on Biomedical Imaging. 2024 <pdf>[</pdf><a href="https://arxiv.org/pdf/2311.06672">PDF</a><pdf>]</pdf> </li>
                    <li><a>Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning</a>. T Suwannaphong, S Chavana, S Tongsom, D Palasuwan, T H Chalidabhongse, and N Anantrasirichai. SN Computer Science. 2023 <pdf>[</pdf><a href="https://link.springer.com/article/10.1007/s42979-023-02406-8">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://zenodo.org/records/10437395">Dataset</a><pdf>]</pdf></li>
                    <li><a>ICIP 2022 Challenge on Parasitic Egg Detection and Classification in Microscopic Images: Dataset, Methods and Results</a>. N Anantrasirichai, TH Chalidabhongse, D Palasuwan, K Naruenatthanaset, T Kobchaisawat, N Nunthanasup, K Boonpeng, X Ma,  and A Achim. IEEE International Conference on Image Processing. 2022. <pdf>[</pdf><a href="https://arxiv.org/pdf/2208.06063.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://ieee-dataport.org/competitions/parasitic-egg-detection-and-classification-microscopic-images">Dataset</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://icip2022challenge.piclab.ai/">Website</a><pdf>]</pdf> </li>
                </ul>
                <h5 id="downloads">Detection in different modalities</h5>
                <ul>

                    <li><a>Anomaly detection for the identification of volcanic unrest in satellite imagery</a>. RG Popescu, N Anantrasirichai, J Biggs. IEEE International Conference on Image Processing. 2024 <pdf>[</pdf><a href="https://arxiv.org/pdf/2405.18487">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://twitter.com/mast_erc">Project</a><pdf>]</pdf> </li>
                    <li><a>Object Recognition in Atmospheric Turbulence Scenes</a>. D Hu, N Anantrasirichai, European Signal Processing Conference. 2023. <pdf>[</pdf><a href="https://arxiv.org/pdf/2210.14318.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://github.com/disen-hu/FasterRcnn_FPN_DCN">CODE</a><pdf>]</pdf></li>
                    <li><a>Detecting Ground Deformation in the Built Environment using Sparse Satellite InSAR data with a Convolutional Neural Network</a>. N. Anantrasirichai, J. Biggs, K. Kelevitz, Z. Sadeghi, T. Wright, J. Thompson, A. Achim and D. Bull.  IEEE Transactions on Geoscience and Remote Sensing. 2020. <pdf>[</pdf><a href="https://arxiv.org/pdf/2005.03221.pdf">PDF</a><pdf>]</pdf> [<a href="https://pui-nantheera.github.io/research/NERC/ground_deformation.html">Project</a>]</li>
                    <li><a>A Deep Learning Approach to Detecting Volcano Deformation from Satellite Imagery using Synthetic Datasets</a>. N. Anantrasirichai, J. Biggs, F. Albino, and David Bull. Remote Sensing of Environment. 2019. <pdf>[</pdf><a href="https://arxiv.org/abs/1905.07286">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://www.sciencedirect.com/science/article/pii/S003442571930183X" target="_blank">BibTeX</a><pdf>]</pdf> [<a href="https://github.com/pui-nantheera/volcano_deform_detection" target="_blank">CODE</a>] [<a href="https://seis.bristol.ac.uk/~eexna\research\volcanicUnrest.html">Project</a>]</li>
                </ul>
            </div>
          

        </div>
    </div>
</body>

</html>
