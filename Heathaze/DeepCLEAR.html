<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
   
    <title>DeepCLEAR</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="../favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon_io/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
</head>

        <!-- you should probably put some google analytics / meta bits and pieces
	    here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '??????????');
  </script>
    -->

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1>DeepCLEAR: Intelligent Atmospheric Turbulence Removal and Object Recognition</h1>
                                <h4><p>AI-Based Methods for Mitigating Atmospheric Distortion </p>
                                <p>and Enhancing Object Detection and Tracking</p></h4>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.svg" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <p><img src="seeingclearly.png" width="100%" /></p>

                <h2 id="aim">Aim</h2>
                <p>Atmospheric turbulence distorts visual imagery, posing significant challenges for information interpretation by both humans and machines. Traditional approaches to mitigating atmospheric turbulence are predominantly model-based, such as <a href="CLEAR.html">CLEAR</a>, but are computationally intensive and memory-demanding, making real-time operations impractical. In contrast, deep learning-based methods have garnered increasing attention but are currently effective primarily for static scenes. This project proposes novel learning-based frameworks specifically designed to support dynamic scenes.</p>

                <p>Our objectives are twofold: (i) to develop real-time video restoration techniques that mitigate spatio-temporal distortions, enhancing the visual interpretation of scenes for human observers, and (ii) to support decision-making by implementing and evaluating real-time object recognition and tracking using the restored video. </p>

        <div class="row">
        <div class="col">
        <dt>Funder</dt>
            <dd>UKRI <a href='https://www.myworld-creates.com/' target="_blank">MyWorld</a> Strength in Places Programme (SIPF00006/1), Defence and Security Accelerator (DASA)</dd>
        </div>
        </div>
        <hr />
       
        <h2 id="downloads">Methods</h2>
        <div class="row">
        <div class="col">
        
            <!-- <h5 id="coreteam">Core</h5> -->
            <ul>
                <li><a>RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator</a> (AAAI2026) <p>[<a href="https://arxiv.org/abs/2508.11409">PDF</a>] [<a href="https://lzm03.github.io/RMFAT/">Project</a>] [<a href="https://github.com/Lzm03/RMFAT/">Code</a>] </p>
                    <p align="left"><img src="RMFAT.jpg" width="100%" /></p>
                    <p>RMFAT, a Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator, restores videos efficiently and consistently by using a lightweight two-input recurrent framework with multi-scale feature encoding and temporal warping to enhance spatial detail and temporal coherence.</p>
                </li>
                
                <li><a>MAMAT: 3D Mamba-Based Atmospheric Turbulence Removal and its Object Detection Capability</a> (AVSS2025) [<a href="https://arxiv.org/pdf/2503.17700?">PDF</a>] [<a href="https://github.com/csprh/MAMAT">Code</a>]
                    <p><p align="left"><img src="MAMAT.jpg" width="100%" /></p></p>
                    <p>MAMAT is a novel Mamba-based method in which the first module employs deformable 3D convolutions for non-rigid registration to reduce spatial shifts, while the second module enhances contrast and detail. Leveraging the advanced capabilities of the 3D Mamba architecture, experimental results demonstrate that MAMAT outperforms state-of-the-art learning-based methods.</p>
                </li>
                <li><a><a>JDATT: A Joint Distillation Framework for Atmospheric Turbulence Mitigation and Target Detection</a>. (BMVC2025) 
                    <pdf>[</pdf><a href="https://arxiv.org/abs/2507.19780">PDF</a><pdf>]</pdf> 
                    <p><p align="middle"><img src="JDATT.jpg" width="60%" /></p></p><p>JDATT is a knowledge distillation framework designed to reduce model size and improve inference speed. We introduce a joint end-to-end training strategy that preserves image quality through reconstruction loss, Channel-Wise Distillation loss, and Masked Generative Distillation loss, while maintaining detection performance via detection loss and Kullbackâ€“Leibler divergence..</p></li>
            </ul>
          
        </div>
        <div class="col">
            <ul>
                <li><a><a>DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection</a>. (WACV2026) 
                    <p>[<a href="https://arxiv.org/pdf/2507.04323">PDF</a>] [<a href="https://github.com/pui-nantheera/DMAT">Code</a>] [<a href="https://zenodo.org/records/17673509">Datasets</a>]</p>
                    <p align="middle"><img src="DMAT.jpg" width="100%" /></p><p>DMAT is an end-to-end framework that jointly improves visual quality and object detection by compensating for distorted features. It enables knowledge exchange between low-level distortion correction in the atmospheric turbulence mitigator and high-level semantic features from the detector. The AT mitigator employs a 3D Mamba-based architecture to model spatio-temporal turbulence effects, and the entire system is optimised jointly.</p></li>
                

                <li><a>DeTurb: Atmospheric Turbulence Mitigation with Deformable 3D Convolutions and 3D Swin Transformers</a> (ACCV2024) 
                    <p><pdf>[</pdf><a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Zou_DeTurb_Atmospheric_Turbulence_Mitigation_with_Deformable_3D_Convolutions_and_3D_ACCV_2024_paper.pdf">PDF</a><pdf>]</pdf> [<a href='https://github.com/Tyreal-Izual/DeTurb' target="_blank">Code</a>]</p>
                    <p align="left"><img src="DeTurb.jpg" width="80%" /></p><p>The DeTurb framework combines geometric restoration with an enhancement module. Random perturbations and geometric distortions are corrected using a pyramid architecture with deformable 3D convolutions, producing aligned frames. These frames are then reconstructed into a sharp, clear image through a multi-scale 3D Swin Transformer architecture.</p></li>
                   
                
            </ul>
          
        </div>
        </div>
        <hr />
        <div class="row">
        <div class="col">
        <h2 id="downloads">Research team</h2>
            <h5 id="coreteam">Core</h5>
            <ul>
                <li><a href='https://pui-nantheera.github.io/'>N. Anantrasirichai</a>: Lead academic</li>
                <li><a href='https://david-bull.github.io/'>D.R. Bull</a> and <a href='https://research-information.bris.ac.uk/en/persons/alin-m-achim'>A. Achim</a>: Co-Lead academics</li>
                <li><a href='https://csprh.github.io/'>Paul Hill</a>: Postdoctoral researcher [</pdf><a href="https://link.springer.com/article/10.1007/s10462-024-11086-6">Review paper</a><pdf>] [<a href="https://arxiv.org/pdf/2503.17700?">Paper1</a>] [<a href="https://arxiv.org/pdf/2402.19041">Paper2</a>] [</pdf><a href="https://zenodo.org/records/13737763">Real dataset</a><pdf>] [<a href="https://zenodo.org/records/17673509">Synthetic datasets</a>]</li>
                <li><a href=''>Zhiming Liu</a>: Research associate [<a href="https://arxiv.org/abs/2507.19780">Paper1</a>] [<a href="https://arxiv.org/abs/2508.11409">Paper2</a>]</li>
            </ul>
            <h5 id="UGteam">Undergrad/Postgrad projects</h5>
            <ul>
                <li>Zhiming Liu (2025), Joint Distillation Framework for Turbulence Mitigation and Target Detection [</pdf><a href="https://arxiv.org/abs/2507.19780">Paper</a><pdf>] 
                <li>Zhicheng (Frederick) Zou (2024), Enhancing Long-Range Imaging through Deep Learning: Mitigating Atmospheric Turbulence [<a href='https://openaccess.thecvf.com/content/ACCV2024/papers/Zou_DeTurb_Atmospheric_Turbulence_Mitigation_with_Deformable_3D_Convolutions_and_3D_ACCV_2024_paper.pdf' target="_blank">Paper</a>] [<a href='https://github.com/Tyreal-Izual/DeTurb' target="_blank">Code</a>]</li> 
                <li>Disen Hu (2022), Atmospheric Turbulence Object Detection in Video Using Deep Learning [<a href='https://eurasip.org/Proceedings/Eusipco/Eusipco2023/pdfs/0000561.pdf' target="_blank">Paper</a>]</li>
                <li><a href='https://research-information.bris.ac.uk/en/persons/rachel-lin'>Rachel Lin</a> (2022), Dealing with Atmospheric Turbulence Distortion in Video Sequences</li>
                <li>Haziq I.B.Mohammed Shafri (2020), Multi-Input Denoising for Atmospheric Turbulence Mitigation in Video</li>
                <li>Jingxuan Wang (2020), Atmospheric turbulence mitigation in video using deep learning</li>
                <li><a href='https://research-information.bris.ac.uk/en/persons/jing-gao-2'>Jing Gao</a> (2019), Atmospheric turbulence removal using convolutional neural network [<a href='https://arxiv.org/pdf/1912.11350' target="_blank">arXiv</a>]</li> 
            </ul>
        </div>
        </div>
            </div>
            <hr />
            
            <div class="container-md">
                <h2 id="downloads">Downloads</h2>
                <h5 id="UGteam">Publications</h5> 
                <ul>
                    <li><a>RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator</a>. Z Liu, N Anantrasirichai, AAAI Conference on Artificial Intelligence. 2026 <pdf>[</pdf><a href="https://arxiv.org/pdf/2508.11409?">PDF</a><pdf>] [<a href="https://lzm03.github.io/RMFAT/">Project</a>] [<a href="https://github.com/Lzm03/RMFAT/">Code</a>]
                    <li><a>DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection</a>. P Hill, Z Liu, A Achim, D Bull, N Anantrasirichai, IEEE/CVF Winter Conference on Applications of Computer Vision. 2026 <pdf>[</pdf><a href="https://arxiv.org/pdf/2505.15737">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://github.com/pui-nantheera/DMAT">CODE</a><pdf>]</pdf> [<a href='hhttps://zenodo.org/records/17673509' target="_blank">Dataset</a>] </li>
                    <li><a>JDATT: A Joint Distillation Framework for Atmospheric Turbulence Mitigation and Target Detection</a>. Z Liu, P Hill, N Anantrasirichai, 36th British Machine Vision Conference. 2025 <pdf>[</pdf><a href="https://arxiv.org/abs/2507.19780">PDF</a><pdf>]</pdf> </li>
                    <li><a>MAMAT: 3D Mamba-Based Atmospheric Turbulence Removal and its Object Detection Capability</a>. P Hill, Z Liu, N Anantrasirichai, 21st IEEE International Conference on Advanced Visual and Signal-Based Systems, 2025 [<a href="https://arxiv.org/pdf/2503.17700?">PDF</a>] [<a href="https://github.com/csprh/MAMAT">Code</a>]</li>
                    <li><a>Deep Learning Techniques for Atmospheric Turbulence Removal: A Review</a>. P Hill, N Anantrasirichai, A Achim, D Bull. Artificial Intelligence Review. 2025 <pdf>[</pdf><a href="https://link.springer.com/article/10.1007/s10462-024-11086-6">PDF</a><pdf>]</pdf> [<a href="https://zenodo.org/records/13737763" target="_blank">ATD Dataset</a>]</li>
                    <li><a>DeTurb: Atmospheric Turbulence Mitigation with Deformable 3D Convolutions and 3D Swin Transformers</a>. Z. Zou and N. Anantrasirichai, Asian Conference on Computer Vision, 2024 <pdf>[</pdf><a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Zou_DeTurb_Atmospheric_Turbulence_Mitigation_with_Deformable_3D_Convolutions_and_3D_ACCV_2024_paper.pdf">PDF</a><pdf>]</pdf> [<a href='https://github.com/Tyreal-Izual/DeTurb' target="_blank">Code</a>] [<a href="https://zenodo.org/records/13737763" target="_blank">ATD Dataset</a>]</li>
                    <li><a>Atmospheric Turbulence Removal with Complex-Valued Convolutional Neural Network</a>. N. Anantrasirichai, Pattern Recognition Letters. 2023 <pdf>[</pdf><a href="https://www.sciencedirect.com/science/article/pii/S0167865523001447">PDF</a><pdf>]</pdf> </li>
                    <li><a>Object Recognition in Atmospheric Turbulence Scenes</a>. D. Hu and N. Anantrasirichai, European Signal Processing Conference. 2023. <pdf>[</pdf><a href="https://arxiv.org/pdf/2210.14318.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://github.com/disen-hu/FasterRcnn_FPN_DCN">Code</a><pdf>]</pdf></li>
                </ul> 
                <h5 id="UGteam">Datasets</h5>
                <ul>
                    <li><a href="https://zenodo.org/records/13737763" target="_blank">ATD</a>: Real atmospheric turbulence dataset (used in <a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Zou_DeTurb_Atmospheric_Turbulence_Mitigation_with_Deformable_3D_Convolutions_and_3D_ACCV_2024_paper.pdf">DeTurb</a>) and <a href="CLEAR.html"  target="_blank">CLEAR</a> results  </li>
                    <li><a href="https://data.bris.ac.uk/data/dataset/1yh1e51t7tg2g2q9cwv96sdfc2"  target="_blank">BVI-CLEAR</a>: Real and synthetic atmospheric turbulence datasets (used in <a href="https://ieeexplore.ieee.org/document/6471221">Paper1</a> and <a href="https://ieeexplore.ieee.org/document/8451755">Paper2</a>) and <a href="CLEAR.html"  target="_blank">CLEAR</a> results </li>
                    <li><a href="https://zenodo.org/records/16986708"  target="_blank">Real AT Dataset</a>: Real atmospheric turbulence datasets (used in <a href="https://ieeexplore.ieee.org/document/6471221">Paper1</a> and <a href="https://ieeexplore.ieee.org/document/8451755">Paper2</a>) and <a href="CLEAR.html"  target="_blank">CLEAR</a> results </li>
                </ul>
            </div>
            <hr />
            
            
            <div class="container-md">
                <h2 id="related">Related research</h2>
                <h5 id="downloads">Related project</h5>
                <ul>
                    <li> <a href="CLEAR.html">CLEAR</a>: Model-based methods for mitigating atmospheric distortions using Dual Tree Complex Wavelet Transform (DT-CWT)</li>
                </ul>

                <h5 id="downloads">Related publications from VI-Lab</h5>
                <ul>
                    <li><a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html" target="_blank">A unified framework for contextual lighting, colorization and denoising for UHD sequences </a>. N Anantrasirichai and D R Bull. IEEE ICIP, 2021</li>
                    <li><a href="https://arxiv.org/pdf/2007.12391.pdf">Artificial intelligence in the creative industries: A review</a>. N Anantrasirichai and D R Bull, Artif Intell Rev 55, 2022</li>
                    <li><a href="https://arxiv.org/abs/2302.08455">ST-MFNet Mini: Knowledge distillation-driven frame interpolation</a>. C Morris, D Danier, F Zhang, N Anantrasirichai, D R Bull. IEEE International Conference on Image Processing. 2023 </li>
                </ul>
                <h5 id="downloads">Denoising in different modalities</h5>
                <ul>
                    <li><a href="https://seis.bristol.ac.uk/~eexna/papers/retinal_img_enhance.pdf">Adaptive-weighted bilateral filtering for optical coherence tomography</a></li>
                    <li><a href="https://ieeexplore.ieee.org/document/9323696">Despeckling SAR Images of the Sea Surface</a></li>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/9160976">Solving SAR Imaging Inverse Problems Using Nonconvex Regularization</a></li>
                    <li><a href="https://www-sigproc.eng.cam.ac.uk/foswiki/pub/Main/NGK/Anantrasirichai_etal_draft_jrnl_12jul2012_c.pdf">Mitigating The Effects of Atmospheric Distortion</a></li>
                </ul>
            </div>
          

        </div>
    </div>
</body>

</html>
